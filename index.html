<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Guanqun Liu</title>
  
  <!-- <meta name="google-site-verification" content="lxQ58o9IgoHyhIPhGGRRwtddDCbfJ0ILZSk-7pjcid4" /> -->
  <meta name="author" content="Hao Zhao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>LIU, Guanqun (åˆ˜ å† ç¾¤)</name>
              </p>
              <p>I received my M.S. degree from the School of Computer and Communication Sciences at <a href="https://www.epfl.ch/en/">EPFL</a> <span>&#127464;&#127469;</span> in Oct 2024, 
                specializing in Medical Image Computing. Previously, I completed my master thesis at EPFL <a href="https://www.epfl.ch/labs/cvlab/">CVLab</a>, supervised by 
                <a href="https://jiancheng-yang.com/">Dr. Jiancheng Yang</a> and <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Prof. Pascal Fua</a>, 
                and will continue my research at TML lab as a research assistant. During my master's, I was also fortunate to spend time as a semester project student at EPFL
                <a href="https://bigwww.epfl.ch/">Biomedical Imaging Group lab</a>, supervised by <a href="https://bigwww.epfl.ch/unser/">Prof. Michael Unser</a>. 
                I received my bachelor's degree from <a href="https://www.polyu.edu.hk/">Hong Kong Polytechnic University</a> <span>&#127464;&#127475;</span>.
              </p>
              <p>
                My research focuses on healthcare AI, with a primary interest on smart medical imaging techniques to assist clinical analysis and personalized treatment planning. Besides,
                I'm also interested in biomedical signal processing, of its combined / multi-modal data integration for comprehensive biomedical representation learning. 
              </p>
              <p>
                I am actively looking for PhD / RA positions starting from 2025 Spring/Fall. If you think I'm a good fit, please don't hesitate to get in touch! 
              </p>
              <p style="text-align:center">
                <!-- <a href="https://scholar.google.com/citations?user=vwWiKP8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a href="mailto:liuguanqun0405@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.ca/citations?user=zir09KwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp -->
                <!-- <a href="https://twitter.com/H_aoZhao">Twitter</a> &nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/guanqun-liu-88b947aa/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/PhilipLGQ">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:80%;max-width:80%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>[Oct 15, 2024] I'm actively finding for a 25 Spring / Fall PhD position or an RA position in healthcare AI in EU/NA! Can't wait to take my step deeper into this field and publish papers in top journals and conferences.
              <p>[Jul 30, 2024] I successfully defended my master's thesis <i>JointAtlas</i> at EPFL CVLab with an outstanding grade of 5.5/6.0. Happy graduation ðŸŽ‰!
              <p>[Jun 30, 2023] I completed my semester project at EPFL BIG Group as an RA with an outstanding grade of 5.5/6.0 ðŸŽ‰.
              <p>[Feb 01, 2023] I completed my 6-month internship at Sony in Stuttgart, with a topic on specular highlight removal and inpainting in surgical images. 
                See Sony's reference for me <a href="data/Sony.pdf">here</a>.
              <p>[Aug 01, 2022] I joined Sony as a computer vision intern in Stuttgart, Germany ðŸŽ‰! 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Projects</heading>
              <!-- <p>
                (* denotes equal contribution)
              </p> -->
              <!-- <p>  
                I'm interested in building machine learning systems that are robust, reliable, trustworthy, and understandable.
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="thesis_stop()" onmouseover="thesis_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='thesis_image'>
                  <img src='images/jointatlas.png' width="160"></div>
                <img src='images/jointatlas.png' width="160">
              </div>
              <script type="text/javascript">
                function thesis_start() {
                  document.getElementById('thesis_image').style.opacity = "1";
                }
  
                function thesis_stop() {
                  document.getElementById('thesis_image').style.opacity = "0";
                }
                thesis_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1k3k-U-1unsDSh0nvrIorKWHRxoPikopE/view?usp=sharing">
                <papertitle><i>JointAtlas</i>: Deformable Template-Based Implicit Method for Joint Segmentation-Appearance Modeling in Cardiac Images </papertitle>
              </a>
              <br>
              <strong>Guanqun Liu</strong>, <a href="https://jiancheng-yang.com/">Jiancheng Yang</a>, <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>
              <br>
              <em>Prepared for preprint</em>
              <br>
              [<a href="https://drive.google.com/file/d/1k3k-U-1unsDSh0nvrIorKWHRxoPikopE/view?usp=sharing">Paper</a>]
              [<a href="https://docs.google.com/presentation/d/1c-0Fm5WXYgdBNVqhIZ1wfCyMhemcQbGe/edit?usp=sharing&ouid=108300918368240195367&rtpof=true&sd=true">Presentation Slides</a>]
              <p></p>
              <p>
                <!-- TO DO -->
                Prior 3D segmentation tasks in medical imaging relies heavily on learning discriminative mappings that learns directly from target's appearance to its substructure segmentations. 
                In this work, we design and validate <i>JointAtlas</i>, a generative mapping approach that jointly models target's appearance and segmentation guided by the implicit field method.
                Inspired by the multi-atlas segmentation (MAS) idea, we propose a deformable latent template-based method to encode the cardiac structures, and to represent any cardiac morphology
                by deforming the latent templates learned from most deviated cardiac shapes from the dataset through our proposed supervised template learning (STL) mechanism. To the best of my
                knowledge, this paper provides the first deformable latent template approach to jointly learn paired segmentation-appearance structures, and it shows superior segmentation performance 
                over current SOTA generative joint mapping methods.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="sair_stop()" onmouseover="sair_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sair_image'>
                  <img src='images/sair.PNG' width="160"></div>
                <img src='images/sair.PNG' width="160">
              </div>
              <script type="text/javascript">
                function sair_start() {
                  document.getElementById('sair_image').style.opacity = "1";
                }
  
                function sair_stop() {
                  document.getElementById('sair_image').style.opacity = "0";
                }
                sair_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2402.04833">
                <papertitle>Deep Neural Networks to Reconstruct Super-Resolution MRI for 3D Modeling</papertitle>
              </a>
              <br>
              <strong>Guanqun Liu</strong>, <a href="https://www.andriushchenko.me/">Dr. Pol del Aguila Pla</a>, 
              <a href="https://scholar.google.com/citations?user=laq9cq0AAAAJ&hl=en">Prof. Michael Unser</a>
              <br>
              [<a href="https://drive.google.com/file/d/1Q7T2jE3jbws51ab0IlpyMmfzg9yS12Do/view?usp=sharing">Report</a>]
              [<a href="https://docs.google.com/presentation/d/1COqm_J-POUfid4hpVruHVjVWJthxNkvn/edit?usp=sharing&ouid=108300918368240195367&rtpof=true&sd=true">Presentation Slides</a>]
              <p></p>
              <p>
                As high-resolution MRI scans takes longer time to process and previous scans do not reserve comparable resolution quality, super-resolution on low-resolution MRI scans
                remains a impactful research topic in medical imaging. In this work, we focus on anisotropic MRI (low-resolution along 1-axis) scans, and design the Single Acquisition
                Isotropic Resolution (SAIR) pipeline - a sample-specific, self-supervised super-resolution pipeline that demonstrated superior performance compared to analytical
                interpolation algorithms and a time-efficient manner with ~10 minutes end-to-end processing time. I also contributed to SAIR's integration to a C++ CAD labeling environment.
              </p>
            </td>
          </tr>


          <tr onmouseout="sony_stop()" onmouseover="sony_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sony_image'>
                  <img src='images/sony.png' width="180"></div>
                <img src='images/sony.png' width="180">
              </div>
              <script type="text/javascript">
                function sony_start() {
                  document.getElementById('sony_image').style.opacity = "1";
                }
  
                function sony_stop() {
                  document.getElementById('sony_image').style.opacity = "0";
                }
                sony_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Specular Highlight Removal and Inpainting in Surgical Images
                </papertitle>
              <br>
              <strong>Guanqun Liu</strong>, <a href="https://www.linkedin.com/in/zoltan-facius-6b424112/?originalSubdomain=de">Zoltan Facius</a>, Dr. Alexander Gatto
              <br>
              <!-- <em>Links:</em> -->
              [<a href="https://drive.google.com/file/d/1BXlFJzQKitfN4hZfAi8qyhU19hJ7BwcR/view?usp=sharing">Reference</a>]
              <p></p>
              <p>
                This internship work was part of Sony's on-going smart clinical solution of surgical robot, with close collaboration between our computational imaging
                group and clinical research group in Tokyo. I was responsible for the visual module block design to tackle specular reflections interfering laporoscopic
                and endoscopic surgeries. With no gold labels in such settings, I designed a specular-free image generator consists of a 2-stage GAN-based network 
                pretrained on lab-conditioned natural objects with a color distribution-based mask correction mechanism in between to perform separate removal and inpainting
                functions on specular images. After careful examination by clinicians, I collected a paired specular-diffuse surgical image dataset and obtained a robust 
                specular reflection removal model through progressive fine-tuning.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Internships</heading>
              <p> [2022.8 - 2023.2] Stuttgart Technology Center, <a href="https://www.sony.com/en/SonyInfo/research/about/stuttgart-laboratory1/">Sony</a>, Germany </p>
              <p> [2019.6 - 2019.8] <a href="https://www.yizhun-ai.com/">Yizhun Medical AI Technology Co., Ltd.</a>, China</p>
            </td>
          </tr>
          </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Education</heading>
            <p> [2021.9 - 2024.8] M.S. in Computer Science, <a href="https://www.epfl.ch/en/">EPFL</a>, Switzerland  (Top ~15%) </p>
            <p> [2017.9 - 2021.6] B.Eng. in Electronic and Information Engineering, <a href="https://www.zju.edu.cn/english/">HKPU</a>, Hong Kong (First Class, Top 10%) </p>
          </td>
        </tr>
        </tbody></table>

      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Review Service</heading>
          <p> Conferences: <a href="https://iclr.cc/">ICLR'25</a>  </p>
          <p> Workshops:  <a href="https://sites.google.com/view/neurips2024-ftw/">FITML@NeurIPS'24</a>,  <a href="https://iclworkshop.github.io/#cfp">ICL@ICML'24</a>, <a href="https://want-ai-hpc.github.io/icml2024/about/">WANT@ICML'24</a>, <a href="https://dmlr.ai/">DMLR@ICLR'24</a> </p>
        </td>
      </tr>
      </tbody></table> -->

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>My Words</heading>
          <p> As one turned to PhD applications from full-time job with determination to pursue my research dream, I realize my greatest weakness is lack of 1st-author publications. Thus I'd also like to be considered
            for RA positions if you think I'm not strong enough for enrolling to a PhD program directly in the competitive field of healthcare AI.
          </p>
          <p> My mother tongue is Madarin Chinese, but I'm also an intermediate-level Cantonese speaker learned during my Bachelor's. I'm proficient in English (TOEFL: 110, C2 level) and can also communicate in
            basic French (~ A2) and Japanese (~ N3). If you don't know how to pronounce my name, see <a href="https://www.mdbg.net/chinese/dictionary?page=worddict&email=&wdrst=0&wdqb=%E5%88%98%E5%86%A0%E7%BE%A4">here</a> or simply call me <i>Philip</i>. </p>
          <p> When I'm free from work, I enjoy hiking &#127939;, and swimming &#127946;, and strength training &#127947;. </p>
        </td>
      </tr>
      </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <strong>Checkout this website layout from <a target="_blank" href="https://jonbarron.info/">here</a>!</strong>
            </p>
            </td>
          </tr>
          </table>

      </td>
    </tr>
  </table>

  
</body>
</html>